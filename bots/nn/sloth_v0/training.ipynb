{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Imports",
   "id": "27166f4a278a8a9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T23:55:59.981914Z",
     "start_time": "2025-03-22T23:55:59.945271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch as t \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sloth_parse import parse_bytearray_string_to_sloth_mlp, parse_bytearray_string_to_sloth_cnn"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Data Preprocessing Functions\n",
    "Can ignore all of this if just training"
   ],
   "id": "3cde928d4ac3e8e5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T17:30:21.126745Z",
     "start_time": "2025-03-22T17:30:21.114420Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_datapoint(datapoint: dict[str, any]) -> dict[str, any]:\n",
    "    \"\"\"\n",
    "    Map function for the dataset to convert the data into a format that can be used by the model.\n",
    "    (viz. convert the state from a bytearray string to a tensor)\n",
    "    Args:\n",
    "        datapoint: the datapoint to be processed\n",
    "\n",
    "    Returns:\n",
    "\n",
    "    \"\"\"\n",
    "    game_state_tensor = parse_bytearray_string_to_sloth_cnn(datapoint['state'])\n",
    "    \n",
    "    wins = int(datapoint['num_wins'])\n",
    "    losses = int(datapoint['num_losses'])\n",
    "    draws = int(datapoint['num_draws'])\n",
    "    num_games = wins + losses + draws\n",
    "    score = t.tensor(0.0 if num_games == 0 else (wins - losses) / num_games)\n",
    "    # this score function attempts to normalize the score to be between -1 and 1, like an evaluation function should\n",
    "    \n",
    "    return {\n",
    "        'tensor_state': game_state_tensor,\n",
    "        'score': score\n",
    "    }\n",
    "    \n",
    "    "
   ],
   "id": "cac4deec33232582",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T17:30:27.284527Z",
     "start_time": "2025-03-22T17:30:27.277107Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_dataset(split: str) -> Dataset:\n",
    "    if split not in ['train', 'validation', 'test']:\n",
    "        raise ValueError(f\"Invalid split: {split}\")\n",
    "    \n",
    "    dataset = load_dataset('markstanl/u3t', split=split)\n",
    "    return dataset"
   ],
   "id": "34fe4c76ff7ef504",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T17:30:43.305632Z",
     "start_time": "2025-03-22T17:30:30.095196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train = get_dataset('train')\n",
    "test = get_dataset('test')\n",
    "val = get_dataset('validation')"
   ],
   "id": "fe0b91ebe128c1ec",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T17:30:43.321693Z",
     "start_time": "2025-03-22T17:30:43.309745Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_tensor_dataset(dataset: Dataset) -> Dataset:\n",
    "    dataset = dataset.remove_columns(['num_visits', 'actions', 'depth'])\n",
    "    \n",
    "    dataset = dataset.map(process_datapoint)\n",
    "    dataset.set_format(type='torch', columns=['tensor_state'])\n",
    "        \n",
    "    dataset = dataset.remove_columns(['state', 'num_wins', 'num_losses', 'num_draws'])\n",
    "    \n",
    "    return dataset\n",
    "    \n",
    "def save_tensor_dataset(dataset: Dataset, split: str):\n",
    "    dataset.to_parquet(f'sloth_{split}.parquet')\n",
    "    \n",
    "def make_tensor_dataset(dataset: Dataset, split: str):\n",
    "    tensor_dataset = get_tensor_dataset(dataset)\n",
    "    save_tensor_dataset(tensor_dataset, split)"
   ],
   "id": "f650128398c68f6b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T19:40:46.798757Z",
     "start_time": "2025-03-22T17:31:12.488817Z"
    }
   },
   "cell_type": "code",
   "source": [
    "make_tensor_dataset(train, 'train')\n",
    "make_tensor_dataset(test, 'test')\n",
    "make_tensor_dataset(val, 'validation')"
   ],
   "id": "4f0ef02d96c953a8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/5601458 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "99a229c1b5ee4e5fa6a3c8553fed7579"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/5602 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b92d548211d14746bf88bbdefabeaabc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/1600367 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77241d6106ef4fa7a199d55e0dd117c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1601 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5c36734b6e8643bbac85a98fee0eeb2d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/800165 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "caa4b55959ed44858687afe212fae972"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/801 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da46b31c50de4ae5b8523a0baf84752b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Though, run this block to get the data loader from your local dataset",
   "id": "7e8e93e24ccbca86"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T23:56:06.700071Z",
     "start_time": "2025-03-22T23:56:06.665009Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_local_data_loader(split: str, cnn: bool=False) -> t.utils.data.DataLoader:\n",
    "    \"\"\"\n",
    "    Get a DataLoader for the given split of the data. Converts the data to tensors.\n",
    "    Args:\n",
    "        split: the split of the data to get the DataLoader for\n",
    "        cnn: boolean to use the cnn split\n",
    "\n",
    "    Returns:\n",
    "        DataLoader: the DataLoader for the given split\n",
    "    \"\"\"\n",
    "    if cnn:\n",
    "        dataset = Dataset.from_parquet(f'sloth_data/sloth_{split}_cnn.parquet')\n",
    "    else:\n",
    "        dataset = Dataset.from_parquet(f'sloth_data/sloth_{split}.parquet')\n",
    "    dataset.set_format(type='torch', columns=['tensor_state', 'score'])\n",
    "    \n",
    "    loader = t.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    return loader\n",
    "\n",
    "def get_loader_from_dataset(dataset: Dataset) -> t.utils.data.DataLoader:\n",
    "    dataset.set_format(type='torch', columns=['tensor_state', 'score'])\n",
    "    \n",
    "    loader = t.utils.data.DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "    return loader\n",
    "\n",
    "def get_local_dataset(split: str) -> Dataset:\n",
    "    return Dataset.from_parquet(f'sloth_data/sloth_{split}.parquet')"
   ],
   "id": "3c26c50955790435",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Sloth ML Construction",
   "id": "765b2e4df3656d1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T19:58:10.071862Z",
     "start_time": "2025-03-20T19:58:10.066642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class Sloth(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(324, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        return self.linear_relu_stack(x)"
   ],
   "id": "9171ed479e9a75ab",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-22T23:56:10.378178Z",
     "start_time": "2025-03-22T23:56:10.346161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def evaluate(model: nn.Module, \n",
    "             loader: t.utils.data.DataLoader, \n",
    "             criterion: t.nn.modules.loss,\n",
    "             num_batches: int = 100):\n",
    "    \n",
    "    model.eval()\n",
    "    with t.no_grad():\n",
    "        total_loss = 0\n",
    "        total_error = 0\n",
    "        num_data_points = 0\n",
    "        \n",
    "        for i, batch in enumerate(loader):\n",
    "            if i >= num_batches:\n",
    "                break\n",
    "            state, score = batch['tensor_state'], batch['score']\n",
    "            output = model(state)\n",
    "            loss = criterion(output, score.unsqueeze(1))\n",
    "            \n",
    "            num_data_points += len(score)\n",
    "            total_loss += loss.item()\n",
    "            total_error += t.sum(t.abs(output - score.unsqueeze(1))).item()\n",
    "        loss = total_loss / num_data_points\n",
    "        error = total_error / num_data_points\n",
    "        \n",
    "        return loss, error\n",
    "    "
   ],
   "id": "747034049b4c5151",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T19:12:00.446599Z",
     "start_time": "2025-03-23T19:12:00.397302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train(model: nn.Module, \n",
    "          loader: t.utils.data.DataLoader, \n",
    "          optimizer: t.optim, \n",
    "          criterion: t.nn.modules.loss, \n",
    "          num_epochs: int,\n",
    "          test_loader: t.utils.data.DataLoader,\n",
    "          epoch_start: int = 0,\n",
    "          path_name: str = None) -> list[tuple[float, float]]:\n",
    "    \"\"\"\n",
    "    Train the model on the given data\n",
    "    Args:\n",
    "        model: the model to train\n",
    "        loader: the DataLoader for the data\n",
    "        optimizer: the optimizer to use\n",
    "        criterion: the loss function to use\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    history = []\n",
    "    save_path = path_name if path_name else \"sloth_models/model_cnn_epoch_{epoch}.pth\"\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "        total_error = 0\n",
    "        num_data_points = 0\n",
    "        \n",
    "        for i, batch in tqdm(enumerate(loader)):\n",
    "            optimizer.zero_grad()\n",
    "            state, score = batch['tensor_state'], batch['score']\n",
    "            output = model(state)\n",
    "            loss = criterion(output, score.unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            num_data_points += len(score)\n",
    "            total_loss += loss.item()\n",
    "            total_error += t.sum(t.abs(output - score.unsqueeze(1))).item()\n",
    "            \n",
    "            # if (i*32) % 500_000 == 0:\n",
    "            #     print(f\"       Iteration {i} Loss: {total_loss / num_data_points} Average Error {total_error / num_data_points}\")\n",
    "                \n",
    "        loss = total_loss / num_data_points\n",
    "        error = total_error / num_data_points\n",
    "                        \n",
    "        if test_loader is None:\n",
    "            print(f\"Epoch {epoch + epoch_start} Loss: {loss} Average Error {error}\")\n",
    "            history.append((loss, error))\n",
    "        else:\n",
    "            test_loss, test_error = evaluate(model, test_loader, criterion, num_batches=100)\n",
    "            print(f\"Epoch {epoch + epoch_start} Loss: {loss} Average Error {error} Test Loss: {test_loss} Test Error: {test_error}\")\n",
    "            history.append((loss, error, test_loss, test_error))\n",
    "        \n",
    "        try:\n",
    "            t.save({\n",
    "                'epoch': epoch+epoch_start+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,  \n",
    "            }, save_path.format(epoch=epoch+epoch_start+1))\n",
    "        except Exception:\n",
    "                        t.save({\n",
    "                'epoch': epoch+epoch_start+1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,  \n",
    "            }, \"sloth_models/backup_model_{epoch}.pth\".format(epoch=epoch+10))\n",
    "        \n",
    "    return history"
   ],
   "id": "119cdb0eb084f4fe",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T19:57:11.872040Z",
     "start_time": "2025-03-20T19:57:00.302622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = get_local_data_loader('train')\n",
    "test_loader = get_local_data_loader('test')"
   ],
   "id": "e742059e3c906f76",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T19:57:11.907279Z",
     "start_time": "2025-03-20T19:57:11.874038Z"
    }
   },
   "cell_type": "code",
   "source": "model_dict = t.load('sloth_models/model_epoch_5.pth')",
   "id": "771301291eb82943",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T19:58:30.016431Z",
     "start_time": "2025-03-20T19:58:29.994689Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = Sloth()\n",
    "model.load_state_dict(model_dict['model_state_dict'])"
   ],
   "id": "35be8cf96fd8e03d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T19:58:38.618404Z",
     "start_time": "2025-03-20T19:58:34.380066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()"
   ],
   "id": "e7e341646f95cfbf",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "history = train(model, train_loader, optimizer, criterion, num_epochs=20, test_loader=test_loader)",
   "id": "6ff6cea89ee71274",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T19:26:19.062901Z",
     "start_time": "2025-03-23T19:26:19.051283Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AlphaU3T_Stride1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlphaU3T_Stride1, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(256 * 9 * 9, 512)  # Assuming input is 9x9\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu4(x)\n",
    "        \n",
    "        x = t.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class AlphaU3T_Deeper(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlphaU3T_Deeper, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(4, 128, kernel_size=3, stride=3, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(128, 256, kernel_size=3, stride=3, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(256, 512)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.relu5 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.relu6 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.float()\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = t.flatten(x, start_dim=1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu5(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu6(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n"
   ],
   "id": "c4b767e49473ed8a",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T19:23:55.332663Z",
     "start_time": "2025-03-23T19:23:41.170066Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn_train_loader = get_local_data_loader('train', cnn=True)\n",
    "cnn_test_loader = get_local_data_loader('test', cnn=True)"
   ],
   "id": "5f8450922bc0e406",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/17 [00:01<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "daeb03143e6f42b49ab9c9779bc869a0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T19:26:21.920086Z",
     "start_time": "2025-03-23T19:26:21.846458Z"
    }
   },
   "cell_type": "code",
   "source": [
    "CNN_deeper = AlphaU3T_Deeper()\n",
    "CNN_low_stride = AlphaU3T_Stride1()"
   ],
   "id": "77dedea2db771ce5",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T19:08:47.965426Z",
     "start_time": "2025-03-23T19:08:47.943158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "deep_optimizer = optim.Adam(CNN_deeper.parameters(), lr=0.01)\n",
    "deep_criterion = nn.MSELoss()\n",
    "\n",
    "small_optimizer = optim.Adam(CNN_low_stride.parameters(), lr=0.01)\n",
    "small_criterion = nn.MSELoss()"
   ],
   "id": "5e3bd6b37078973a",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T23:49:53.272098Z",
     "start_time": "2025-03-23T19:26:23.756468Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history_deep = train(CNN_deeper, cnn_train_loader, deep_optimizer, deep_criterion, num_epochs=3, test_loader=cnn_test_loader, path_name= \"sloth_models/deep_{epoch}.pth\")\n",
    "history_small = train(CNN_low_stride, cnn_train_loader, small_optimizer, small_criterion, num_epochs=3, test_loader=cnn_test_loader, path_name= \"sloth_models/small_{epoch}.pth\")"
   ],
   "id": "9e04bb6d50855b7d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175046it [3:16:36, 14.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.003667584357230146 Average Error 0.1970615961488724 Test Loss: 0.003665852502454072 Test Error: 0.19781354919075966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175046it [3:15:32, 14.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.0036675846930803203 Average Error 0.1970615961358692 Test Loss: 0.0035742034472059456 Test Error: 0.19446256175637244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175046it [3:14:28, 15.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 0.0036675917222465547 Average Error 0.19706159615083033 Test Loss: 0.00369506279588677 Test Error: 0.19628638960421085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175046it [9:00:49,  5.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 0.003652560282939212 Average Error 0.19527091542639669 Test Loss: 0.003527253976208158 Test Error: 0.19072815373539925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175046it [9:13:18,  5.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 0.00365256787968044 Average Error 0.19527091539862387 Test Loss: 0.0037444021744886414 Test Error: 0.1963022192567587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7132it [21:58,  5.41it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[51], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m history_deep \u001B[38;5;241m=\u001B[39m train(CNN_deeper, cnn_train_loader, deep_optimizer, deep_criterion, num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, test_loader\u001B[38;5;241m=\u001B[39mcnn_test_loader, path_name\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msloth_models/deep_\u001B[39m\u001B[38;5;132;01m{epoch}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m----> 2\u001B[0m history_small \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCNN_low_stride\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcnn_train_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msmall_optimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msmall_criterion\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcnn_test_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpath_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msloth_models/small_\u001B[39;49m\u001B[38;5;132;43;01m{epoch}\u001B[39;49;00m\u001B[38;5;124;43m.pth\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[41], line 26\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(model, loader, optimizer, criterion, num_epochs, test_loader, epoch_start, path_name)\u001B[0m\n\u001B[0;32m     23\u001B[0m total_error \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     24\u001B[0m num_data_points \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 26\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     28\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstate\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mscore\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtensor_state\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mscore\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\tqdm\\std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[0;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m   1182\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[0;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[0;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:708\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    705\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    707\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 708\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    709\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    710\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    711\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    712\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    713\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    714\u001B[0m ):\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:764\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    762\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    763\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 764\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    765\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    766\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:2786\u001B[0m, in \u001B[0;36mDataset.__getitems__\u001B[1;34m(self, keys)\u001B[0m\n\u001B[0;32m   2784\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__getitems__\u001B[39m(\u001B[38;5;28mself\u001B[39m, keys: List) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List:\n\u001B[0;32m   2785\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001B[39;00m\n\u001B[1;32m-> 2786\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getitem__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mkeys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2787\u001B[0m     n_examples \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(batch[\u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(batch))])\n\u001B[0;32m   2788\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [{col: array[i] \u001B[38;5;28;01mfor\u001B[39;00m col, array \u001B[38;5;129;01min\u001B[39;00m batch\u001B[38;5;241m.\u001B[39mitems()} \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_examples)]\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:2782\u001B[0m, in \u001B[0;36mDataset.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2780\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, key):  \u001B[38;5;66;03m# noqa: F811\u001B[39;00m\n\u001B[0;32m   2781\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001B[39;00m\n\u001B[1;32m-> 2782\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_getitem\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\arrow_dataset.py:2767\u001B[0m, in \u001B[0;36mDataset._getitem\u001B[1;34m(self, key, **kwargs)\u001B[0m\n\u001B[0;32m   2765\u001B[0m formatter \u001B[38;5;241m=\u001B[39m get_formatter(format_type, features\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_info\u001B[38;5;241m.\u001B[39mfeatures, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mformat_kwargs)\n\u001B[0;32m   2766\u001B[0m pa_subtable \u001B[38;5;241m=\u001B[39m query_table(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_data, key, indices\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_indices)\n\u001B[1;32m-> 2767\u001B[0m formatted_output \u001B[38;5;241m=\u001B[39m \u001B[43mformat_table\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   2768\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpa_subtable\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformatter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformatter\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mformat_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mformat_columns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_all_columns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_all_columns\u001B[49m\n\u001B[0;32m   2769\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2770\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m formatted_output\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\formatting\\formatting.py:666\u001B[0m, in \u001B[0;36mformat_table\u001B[1;34m(table, key, formatter, format_columns, output_all_columns)\u001B[0m\n\u001B[0;32m    664\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    665\u001B[0m     pa_table_to_format \u001B[38;5;241m=\u001B[39m pa_table\u001B[38;5;241m.\u001B[39mdrop(col \u001B[38;5;28;01mfor\u001B[39;00m col \u001B[38;5;129;01min\u001B[39;00m pa_table\u001B[38;5;241m.\u001B[39mcolumn_names \u001B[38;5;28;01mif\u001B[39;00m col \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m format_columns)\n\u001B[1;32m--> 666\u001B[0m     formatted_output \u001B[38;5;241m=\u001B[39m \u001B[43mformatter\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table_to_format\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mquery_type\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    667\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m output_all_columns:\n\u001B[0;32m    668\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(formatted_output, MutableMapping):\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\formatting\\formatting.py:415\u001B[0m, in \u001B[0;36mFormatter.__call__\u001B[1;34m(self, pa_table, query_type)\u001B[0m\n\u001B[0;32m    413\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat_column(pa_table)\n\u001B[0;32m    414\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m query_type \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m--> 415\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpa_table\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:121\u001B[0m, in \u001B[0;36mTorchFormatter.format_batch\u001B[1;34m(self, pa_table)\u001B[0m\n\u001B[0;32m    119\u001B[0m batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnumpy_arrow_extractor()\u001B[38;5;241m.\u001B[39mextract_batch(pa_table)\n\u001B[0;32m    120\u001B[0m batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpython_features_decoder\u001B[38;5;241m.\u001B[39mdecode_batch(batch)\n\u001B[1;32m--> 121\u001B[0m batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecursive_tensorize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    122\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m column_name \u001B[38;5;129;01min\u001B[39;00m batch:\n\u001B[0;32m    123\u001B[0m     batch[column_name] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consolidate(batch[column_name])\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:104\u001B[0m, in \u001B[0;36mTorchFormatter.recursive_tensorize\u001B[1;34m(self, data_struct)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrecursive_tensorize\u001B[39m(\u001B[38;5;28mself\u001B[39m, data_struct: \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m--> 104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmap_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_recursive_tensorize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\utils\\py_utils.py:512\u001B[0m, in \u001B[0;36mmap_nested\u001B[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001B[0m\n\u001B[0;32m    509\u001B[0m         batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mlen\u001B[39m(iterable) \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m/\u001B[39m num_proc \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mint\u001B[39m(\u001B[38;5;28mlen\u001B[39m(iterable) \u001B[38;5;241m%\u001B[39m num_proc \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m), \u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m    510\u001B[0m     iterable \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(iter_batched(iterable, batch_size))\n\u001B[0;32m    511\u001B[0m mapped \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m--> 512\u001B[0m     \u001B[43m_single_map_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatched\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtypes\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    513\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m hf_tqdm(iterable, disable\u001B[38;5;241m=\u001B[39mdisable_tqdm, desc\u001B[38;5;241m=\u001B[39mdesc)\n\u001B[0;32m    514\u001B[0m ]\n\u001B[0;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batched:\n\u001B[0;32m    516\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m [mapped_item \u001B[38;5;28;01mfor\u001B[39;00m mapped_batch \u001B[38;5;129;01min\u001B[39;00m mapped \u001B[38;5;28;01mfor\u001B[39;00m mapped_item \u001B[38;5;129;01min\u001B[39;00m mapped_batch]\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\utils\\py_utils.py:373\u001B[0m, in \u001B[0;36m_single_map_nested\u001B[1;34m(args)\u001B[0m\n\u001B[0;32m    371\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m function([data_struct])[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m    372\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 373\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    374\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    375\u001B[0m     batched\n\u001B[0;32m    376\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, \u001B[38;5;28mdict\u001B[39m)\n\u001B[0;32m    377\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, types)\n\u001B[0;32m    378\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mall\u001B[39m(\u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(v, (\u001B[38;5;28mdict\u001B[39m, types)) \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m data_struct)\n\u001B[0;32m    379\u001B[0m ):\n\u001B[0;32m    380\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [mapped_item \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m iter_batched(data_struct, batch_size) \u001B[38;5;28;01mfor\u001B[39;00m mapped_item \u001B[38;5;129;01min\u001B[39;00m function(batch)]\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:98\u001B[0m, in \u001B[0;36mTorchFormatter._recursive_tensorize\u001B[1;34m(self, data_struct)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_struct\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:  \u001B[38;5;66;03m# torch tensors cannot be instantied from an array of objects\u001B[39;00m\n\u001B[1;32m---> 98\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consolidate([\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecursive_tensorize\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubstruct\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m substruct \u001B[38;5;129;01min\u001B[39;00m data_struct])\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consolidate([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecursive_tensorize(substruct) \u001B[38;5;28;01mfor\u001B[39;00m substruct \u001B[38;5;129;01min\u001B[39;00m data_struct])\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:104\u001B[0m, in \u001B[0;36mTorchFormatter.recursive_tensorize\u001B[1;34m(self, data_struct)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrecursive_tensorize\u001B[39m(\u001B[38;5;28mself\u001B[39m, data_struct: \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m--> 104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmap_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_recursive_tensorize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\utils\\py_utils.py:484\u001B[0m, in \u001B[0;36mmap_nested\u001B[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batched:\n\u001B[0;32m    483\u001B[0m     data_struct \u001B[38;5;241m=\u001B[39m [data_struct]\n\u001B[1;32m--> 484\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batched:\n\u001B[0;32m    486\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m mapped[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:98\u001B[0m, in \u001B[0;36mTorchFormatter._recursive_tensorize\u001B[1;34m(self, data_struct)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_struct\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:  \u001B[38;5;66;03m# torch tensors cannot be instantied from an array of objects\u001B[39;00m\n\u001B[1;32m---> 98\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consolidate([\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecursive_tensorize\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubstruct\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m substruct \u001B[38;5;129;01min\u001B[39;00m data_struct])\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consolidate([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecursive_tensorize(substruct) \u001B[38;5;28;01mfor\u001B[39;00m substruct \u001B[38;5;129;01min\u001B[39;00m data_struct])\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:104\u001B[0m, in \u001B[0;36mTorchFormatter.recursive_tensorize\u001B[1;34m(self, data_struct)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrecursive_tensorize\u001B[39m(\u001B[38;5;28mself\u001B[39m, data_struct: \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m--> 104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmap_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_recursive_tensorize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\utils\\py_utils.py:484\u001B[0m, in \u001B[0;36mmap_nested\u001B[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batched:\n\u001B[0;32m    483\u001B[0m     data_struct \u001B[38;5;241m=\u001B[39m [data_struct]\n\u001B[1;32m--> 484\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batched:\n\u001B[0;32m    486\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m mapped[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:98\u001B[0m, in \u001B[0;36mTorchFormatter._recursive_tensorize\u001B[1;34m(self, data_struct)\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, np\u001B[38;5;241m.\u001B[39mndarray):\n\u001B[0;32m     97\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_struct\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:  \u001B[38;5;66;03m# torch tensors cannot be instantied from an array of objects\u001B[39;00m\n\u001B[1;32m---> 98\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consolidate([\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecursive_tensorize\u001B[49m\u001B[43m(\u001B[49m\u001B[43msubstruct\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m substruct \u001B[38;5;129;01min\u001B[39;00m data_struct])\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consolidate([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecursive_tensorize(substruct) \u001B[38;5;28;01mfor\u001B[39;00m substruct \u001B[38;5;129;01min\u001B[39;00m data_struct])\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:104\u001B[0m, in \u001B[0;36mTorchFormatter.recursive_tensorize\u001B[1;34m(self, data_struct)\u001B[0m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mrecursive_tensorize\u001B[39m(\u001B[38;5;28mself\u001B[39m, data_struct: \u001B[38;5;28mdict\u001B[39m):\n\u001B[1;32m--> 104\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmap_nested\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_recursive_tensorize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmap_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\utils\\py_utils.py:484\u001B[0m, in \u001B[0;36mmap_nested\u001B[1;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batched:\n\u001B[0;32m    483\u001B[0m     data_struct \u001B[38;5;241m=\u001B[39m [data_struct]\n\u001B[1;32m--> 484\u001B[0m mapped \u001B[38;5;241m=\u001B[39m \u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batched:\n\u001B[0;32m    486\u001B[0m     mapped \u001B[38;5;241m=\u001B[39m mapped[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:101\u001B[0m, in \u001B[0;36mTorchFormatter._recursive_tensorize\u001B[1;34m(self, data_struct)\u001B[0m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data_struct, (\u001B[38;5;28mlist\u001B[39m, \u001B[38;5;28mtuple\u001B[39m)):\n\u001B[0;32m    100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_consolidate([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrecursive_tensorize(substruct) \u001B[38;5;28;01mfor\u001B[39;00m substruct \u001B[38;5;129;01min\u001B[39;00m data_struct])\n\u001B[1;32m--> 101\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tensorize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_struct\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\utt-file-extension\\.venv\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:87\u001B[0m, in \u001B[0;36mTorchFormatter._tensorize\u001B[1;34m(self, value)\u001B[0m\n\u001B[0;32m     84\u001B[0m         value\u001B[38;5;241m.\u001B[39m_hf_bridge_out \u001B[38;5;241m=\u001B[39m to_torch\n\u001B[0;32m     85\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[1;32m---> 87\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdefault_dtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtorch_tensor_kwargs\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T23:53:55.790669Z",
     "start_time": "2025-03-24T23:53:55.779811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with open('sloth_models/cnn_history', 'w') as f:\n",
    "    f.write(\"history_deep:\\n\")\n",
    "    for item in history_deep:\n",
    "        f.write(str(item) + \"\\n\")\n",
    "\n",
    "    f.write(\"\\n\\nhistory_small:\\n\")\n",
    "    f.write(\"Epoch 0 Loss: 0.003652560282939212 Average Error 0.19527091542639669 Test Loss: 0.003527253976208158 Test Error: 0.19072815373539925\")\n",
    "    f.write(\"Epoch 1 Loss: 0.00365256787968044 Average Error 0.19527091539862387 Test Loss: 0.0037444021744886414 Test Error: 0.1963022192567587\")\n",
    "    "
   ],
   "id": "960bfba33ff48657",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BetaGo ML Construction",
   "id": "70abe5e9c8dd631d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T00:26:51.329663Z",
     "start_time": "2025-03-23T00:26:51.314366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class AlphaU3T(nn.Module):\n",
    "    \"\"\"\n",
    "    The AlphaU3T model takes inspiration from the AlphaGo from Google model for the game go. Specifically, it takes inspiration from the\n",
    "    value model associated with the model. Though, it is learned on a much smaller model\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(AlphaU3T, self).__init__()\n",
    "        \n",
    "        # convolutional layer\n",
    "        self.conv1 = nn.Conv2d(4, 32, kernel_size=3, stride=3, padding=0)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=3, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        # dense layers\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.relu4 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward Method\n",
    "        \"\"\"\n",
    "        x = x.float()\n",
    "        \n",
    "        # convolutional layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = t.flatten(x, start_dim=1) \n",
    "        \n",
    "        # dense layers\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu4(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        return x"
   ],
   "id": "51a29562995a8af6",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T00:26:53.401331Z",
     "start_time": "2025-03-23T00:26:53.392692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cnn_model = AlphaU3T()\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=0.01)\n",
    "criterion = nn.MSELoss()"
   ],
   "id": "635c7925c2b31575",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T00:17:53.053975Z",
     "start_time": "2025-03-23T00:14:51.924917Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = get_local_data_loader('train', True)\n",
    "test_loader = get_local_data_loader('test', True)"
   ],
   "id": "ae21702bd42a24fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "be8e53d50a8b4cb29f6551aefccb28fb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Loading dataset shards:   0%|          | 0/17 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcd3535418f949eaa0398d6143d9f58f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55de267d50384f6b8818823d2c0a89af"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T00:23:57.308950Z",
     "start_time": "2025-03-23T00:23:55.308495Z"
    }
   },
   "cell_type": "code",
   "source": "example = next(iter(train_loader))",
   "id": "b3a8545ef312cec7",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T00:25:27.349548Z",
     "start_time": "2025-03-23T00:25:27.343075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tensor_example = example['tensor_state'][0]\n",
    "print(tensor_example.shape)"
   ],
   "id": "e6081f6db43fee12",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 9, 9])\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T15:54:22.484741Z",
     "start_time": "2025-03-23T00:29:19.161637Z"
    }
   },
   "cell_type": "code",
   "source": "history_cnn = train(cnn_model, train_loader, optimizer, criterion, num_epochs=5, test_loader=test_loader, epoch_start=6)",
   "id": "bfd00660b91e372f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175046it [3:08:42, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 0.003656460857605309 Average Error 0.19787686282437814 Test Loss: 0.003802773815114051 Test Error: 0.20328570924699307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175046it [3:09:28, 15.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 Loss: 0.0036565309992870544 Average Error 0.19787002246452515 Test Loss: 0.003543241294682957 Test Error: 0.19356504410505296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175046it [3:04:30, 15.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 Loss: 0.003656558411508088 Average Error 0.19786868054750925 Test Loss: 0.0036529532074928285 Test Error: 0.19978500708937644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175046it [3:04:12, 15.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 Loss: 0.0036565793443913692 Average Error 0.19788149627265517 Test Loss: 0.003708244788867887 Test Error: 0.19693719387054442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "175046it [2:57:32, 16.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Loss: 0.0036564562905072725 Average Error 0.19787700443464767 Test Loss: 0.0036842143334797585 Test Error: 0.19886592507362366\n"
     ]
    }
   ],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T18:59:36.240561Z",
     "start_time": "2025-03-23T18:59:36.214235Z"
    }
   },
   "cell_type": "code",
   "source": "print(history_cnn)",
   "id": "400cd245b2a1cf6b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.003656460857605309, 0.19787686282437814, 0.003802773815114051, 0.20328570924699307), (0.0036565309992870544, 0.19787002246452515, 0.003543241294682957, 0.19356504410505296), (0.003656558411508088, 0.19786868054750925, 0.0036529532074928285, 0.19978500708937644), (0.0036565793443913692, 0.19788149627265517, 0.003708244788867887, 0.19693719387054442), (0.0036564562905072725, 0.19787700443464767, 0.0036842143334797585, 0.19886592507362366)]\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Understanding Data Conversion\n",
    "I am having trouble with the tensors in the dataset. I realized the issue was with loading datasets as tensors from the parquet file, the solution is to set the format of the dataset to torch when loading."
   ],
   "id": "cdbd96a8412cad21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2a3b116f5daf4cebb25985e8ab32c16f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 'state': string\n",
      "Column 'num_wins': int64\n",
      "Column 'num_draws': int64\n",
      "Column 'num_losses': int64\n",
      "Column 'tensor_state': list\n",
      "Column 'score': float32\n"
     ]
    }
   ],
   "execution_count": 131,
   "source": [
    "train_test = train[:10]\n",
    "train_test_dataset = Dataset.from_dict(train_test)\n",
    "\n",
    "tensor_dataset = get_tensor_dataset(train_test_dataset)"
   ],
   "id": "e6e4844fca94dc2c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0a7a3fe87e0a433ba4871f2dcbd24397"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7b236f570d36491180aae7a0c546b2a6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 136,
   "source": [
    "make_tensor_dataset(train_test_dataset, 'train_test')\n",
    "loader = get_local_data_loader('train_test')"
   ],
   "id": "c4df577d0475b985"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 137,
   "source": "batch = next(iter(loader))",
   "id": "96c09801d7031029"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "execution_count": 138,
   "source": [
    "example = batch['tensor_state'][0]\n",
    "print(type(example))"
   ],
   "id": "187224941e98defb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 81])\n"
     ]
    }
   ],
   "execution_count": 140,
   "source": "print(example.shape)",
   "id": "3157f82d0925ba9d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 1., 1.,  ..., 1., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0., 0., 1.,  ..., 1., 1., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [1., 1., 1.,  ..., 1., 1., 1.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 1.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "         [0., 0., 0.,  ..., 0., 0., 0.]]]) torch.Size([10, 4, 81])\n",
      "tensor([[1., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [1., 0., 0.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 1.,  ..., 1., 1., 1.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]) torch.Size([10, 324])\n",
      "tensor([[-0.0249],\n",
      "        [-0.0343],\n",
      "        [-0.0330],\n",
      "        [-0.0233],\n",
      "        [-0.0146],\n",
      "        [-0.0203],\n",
      "        [-0.0236],\n",
      "        [-0.0324],\n",
      "        [-0.0169],\n",
      "        [-0.0175]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "execution_count": 149,
   "source": [
    "tensors = batch['tensor_state']\n",
    "print(model(tensors))"
   ],
   "id": "e81df9a495a70af9"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluation",
   "id": "449403f2c4edeb68"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "test_loader = get_local_data_loader('test')",
   "id": "468b049fedb8f5c5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "evaluate(model, test_loader)",
   "id": "12949e2aa7a3032f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualization",
   "id": "426be0494a766ed4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:36:17.762978Z",
     "start_time": "2025-03-20T16:36:14.619991Z"
    }
   },
   "cell_type": "code",
   "source": "test_set = get_local_dataset('test')\n",
   "id": "bf8961d00abfaf3e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['tensor_state', 'score'],\n",
      "    num_rows: 1600367\n",
      "})\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:36:40.276615Z",
     "start_time": "2025-03-20T16:36:38.178443Z"
    }
   },
   "cell_type": "code",
   "source": "scores = test_set['score']",
   "id": "32e01baf42f62891",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:41:06.665843Z",
     "start_time": "2025-03-20T16:41:06.660990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "id": "cb393ceca1552bea",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-20T16:42:07.773627Z",
     "start_time": "2025-03-20T16:42:05.066250Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(scores)\n",
    "counts, bins = np.histogram(scores)\n",
    "plt.stairs(counts, bins)\n",
    "plt.show()\n"
   ],
   "id": "5be1f71b70c9f4b3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "afb9244d92bd36cb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
